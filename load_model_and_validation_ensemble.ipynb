{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models.segmentation as segmentation\n",
    "import segmentation_models_pytorch as smp\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.transforms as transforms\n",
    "from albumentations.core.composition import Compose\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLE decoding/encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 디코딩 함수\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = \"./path/save/resnet50_l2/\"  # 모델 저장 디렉토리\n",
    "# model_name = \"deeplabv3_resnet50_l2_trained_epoch{}.pth\"  # 모델 파일 이름 패턴\n",
    "\n",
    "# # 훈련된 모델을 저장하는 함수\n",
    "# def save_model(model, epoch):\n",
    "#     save_path = save_dir + model_name.format(epoch)\n",
    "#     torch.save(model.state_dict(), save_path)\n",
    "#     print(f\"Epoch {epoch} 모델 저장이 완료되었습니다.\")\n",
    "\n",
    "# 모델 불러오는 함수\n",
    "def load_model(model, load_path):\n",
    "    state_dict = torch.load(load_path)\n",
    "    # 이전에 저장된 모델과 현재 모델 간 레이어 일치 여부 확인\n",
    "    model_dict = model.state_dict()\n",
    "    new_state_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "    model_dict.update(new_state_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(\"모델 불러오기가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False): # transform 전처리하거나 다른 형태로 변환하는데 사용, infer 데이터를 추론 모드로 설정할지 여부\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 1] # 해당 인덱스에 위치한 데이터프레임의 두 번째 열(column)에 있는 이미지 경로를 가져옴\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "        mask_rle = self.data.iloc[idx, 2] # 데이터프레임의 idx 행에서 세 번째 열(column)에 있는 마스크 정보를 가져옴\n",
    "        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1])) # 원래의 마스크 이미지로 변환\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask) # 이미지와 마스크를 변환\n",
    "            image = augmented['image'] # 변환된 이미지를 딕셔너리에서 가져와 image 변수에 할당\n",
    "            mask = augmented['mask'] # 변환된 이미지를 딕셔너리에서 가져와 mask 변수에 할당\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albumentations 라이브러리를 사용하여 이미지 데이터에 대한 변환(transform) 파이프라인 정의\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        # A.Resize(224, 224), # 이미지 크기 조정\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 이미지 픽셀값 정규화\n",
    "        ToTensorV2() # 이미지를 텐서로 변환\n",
    "    ]\n",
    ")\n",
    "\n",
    "# # 데이터 증강을 위한 transform 파이프라인 정의\n",
    "# transform = A.Compose(\n",
    "#     [\n",
    "#         A.Resize(224, 224),  # 이미지 크기 조정\n",
    "#         A.RandomCrop(224, 224),  # 랜덤한 위치에서 224x224 크기로 자르기\n",
    "#         A.RandomRotate90(),  # 90도 회전 (랜덤하게)\n",
    "#         A.HorizontalFlip(p=0.5),  # 수평 뒤집기 확률 50%\n",
    "#         A.VerticalFlip(p=0.5),  # 수직 뒤집기 확률 50%\n",
    "#         A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.7),  # 이동, 크기 조정, 회전\n",
    "#         A.CLAHE(p=0.2),  # CLAHE를 통한 대비 개선\n",
    "#         A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, p=0.5),  # Cutout 적용\n",
    "#         A.Normalize(),  # 이미지 픽셀값 정규화\n",
    "#         ToTensorV2()  # 이미지를 텐서로 변환\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# dataset = SatelliteDataset(csv_file='./train.csv', transform=transform) # dataset 불러오기\n",
    "# dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60640\n",
      "3790\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SatelliteDataset(csv_file='./test.csv', transform=transform, infer=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "print(len(test_dataset))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): DeepLabHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 모델 생성\n",
    "# model1 = smp.Unet(encoder_name=\"resnet50\",  # 필수 파라미터: 사용할 인코더 백본의 이름\n",
    "#     in_channels=3,    # 필수 파라미터: 입력 이미지의 채널 수 (일반적으로 3(RGB) 또는 1(Grayscale))\n",
    "#     classes=1,        # 필수 파라미터: 세그멘테이션 클래스의 수 (예: 물체 탐지의 경우 물체 클래스 수)\n",
    "#     encoder_weights=\"imagenet\"  # 선택적 파라미터: 사용할 사전 훈련된 인코더 가중치의 경로 또는 'imagenet'으로 설정하여 ImageNet 가중치 사용\n",
    "# )\n",
    "\n",
    "# DeepLabV3+ 모델 정의\n",
    "model1 = smp.PSPNet(encoder_name=\"resnet152\",  # 필수 파라미터: 사용할 인코더 백본의 이름\n",
    "    in_channels=3,    # 필수 파라미터: 입력 이미지의 채널 수 (일반적으로 3(RGB) 또는 1(Grayscale))\n",
    "    classes=1,        # 필수 파라미터: 세그멘테이션 클래스의 수 (예: 물체 탐지의 경우 물체 클래스 수)\n",
    "    encoder_weights=\"imagenet\"  # 선택적 파라미터: 사용할 사전 훈련된 인코더 가중치의 경로 또는 'imagenet'으로 설정하여 ImageNet 가중치 사용\n",
    ")\n",
    "\n",
    "model2 = smp.PSPNet(\n",
    "    encoder_name=\"densenet161\",   # 백본으로 ResNet-50 사용\n",
    "    encoder_weights=\"imagenet\", # ImageNet 가중치로 초기화\n",
    "    in_channels=3,             # 입력 이미지 채널 수 (RGB 이미지인 경우 3)\n",
    "    classes=1                  # 출력 클래스 수 (이진 분류인 경우 1)\n",
    ")\n",
    "\n",
    "model3 = smp.Unet(encoder_name=\"resnet50\",  # 필수 파라미터: 사용할 인코더 백본의 이름\n",
    "    in_channels=3,    # 필수 파라미터: 입력 이미지의 채널 수 (일반적으로 3(RGB) 또는 1(Grayscale))\n",
    "    classes=1,        # 필수 파라미터: 세그멘테이션 클래스의 수 (예: 물체 탐지의 경우 물체 클래스 수)\n",
    "    encoder_weights=\"imagenet\"  # 선택적 파라미터: 사용할 사전 훈련된 인코더 가중치의 경로 또는 'imagenet'으로 설정하여 ImageNet 가중치 사용\n",
    ")\n",
    "\n",
    "model4 = smp.DeepLabV3Plus(encoder_name=\"timm-mobilenetv3_large_100\",  # 필수 파라미터: 사용할 인코더 백본의 이름\n",
    "    in_channels=3,    # 필수 파라미터: 입력 이미지의 채널 수 (일반적으로 3(RGB) 또는 1(Grayscale))\n",
    "    classes=1,        # 필수 파라미터: 세그멘테이션 클래스의 수 (예: 물체 탐지의 경우 물체 클래스 수)\n",
    "    encoder_weights=\"imagenet\"  # 선택적 파라미터: 사용할 사전 훈련된 인코더 가중치의 경로 또는 'imagenet'으로 설정하여 ImageNet 가중치 사용\n",
    ")\n",
    "\n",
    "model5 = smp.DeepLabV3Plus(encoder_name=\"timm-mobilenetv3_large_100\",  # 필수 파라미터: 사용할 인코더 백본의 이름\n",
    "    in_channels=3,    # 필수 파라미터: 입력 이미지의 채널 수 (일반적으로 3(RGB) 또는 1(Grayscale))\n",
    "    classes=1,        # 필수 파라미터: 세그멘테이션 클래스의 수 (예: 물체 탐지의 경우 물체 클래스 수)\n",
    "    encoder_weights=\"imagenet\"  # 선택적 파라미터: 사용할 사전 훈련된 인코더 가중치의 경로 또는 'imagenet'으로 설정하여 ImageNet 가중치 사용\n",
    ")\n",
    "\n",
    "model6 = segmentation.deeplabv3_resnet50(pretrained=True) # 사전 훈련된 deeplabv3 모델 가져옴, pretrained=True이면 모델이 사전 훈련된 가중치 사용하여 초기화됨\n",
    "model6.classifier[4] = nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1)) # 1*1 컨볼루션 레이어 생성, 입력 채널 256, 출력 채널 1로 설정\n",
    "# model = model.to(device)\n",
    "\n",
    "# 저장된 모델의 파라미터 불러오기 (strict=False 옵션 사용)\n",
    "state_dict_1 = torch.load('./path/save/ensemble/psp_resnet_trained_epoch13.pth', map_location=torch.device('cpu'))\n",
    "state_dict_2 = torch.load('./path/save/ensemble/psp_dense_base_trained_epoch55.pth', map_location=torch.device('cpu'))\n",
    "state_dict_3 = torch.load('./path/save/ensemble/unet_resnet_50_new_aug_noempty_trained_epoch32.pth', map_location=torch.device('cpu'))\n",
    "state_dict_4 = torch.load('./path/save/ensemble/v3plus_mobilenet_epoch42.pth', map_location=torch.device('cpu'))\n",
    "state_dict_5 = torch.load('./path/save/ensemble/mobileNet_focal_dice_trained_epoch23.pth', map_location=torch.device('cpu'))\n",
    "state_dict_6 = torch.load('./path/save/ensemble/deeplabv3_resnet50_focal_dice_batch8_trained_epoch40.pth', map_location=torch.device('cpu'))\n",
    "\n",
    "# # 저장된 모델의 클래스 수 (1개의 클래스일 때)\n",
    "# saved_num_classes = 1\n",
    "\n",
    "# # 현재 모델의 클래스 수 (예시로 21로 설정, 실제 사용하는 클래스 수로 수정)\n",
    "# current_num_classes = 1\n",
    "\n",
    "# # 모델의 분류기 레이어 크기 변경\n",
    "# if saved_num_classes != current_num_classes:\n",
    "#     # 모델의 분류기 레이어를 1x1 컨볼루션 레이어로 수정\n",
    "#     model.classifier[4] = torch.nn.Conv2d(256, current_num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
    "#     # 모델의 분류기 레이어를 초기화\n",
    "#     torch.nn.init.xavier_uniform_(model.classifier[4].weight)  # 또는 다른 초기화 방법 사용\n",
    "\n",
    "# 모델의 파라미터 로드\n",
    "model1.load_state_dict(state_dict_1, strict=False)\n",
    "model2.load_state_dict(state_dict_2, strict=False)\n",
    "model3.load_state_dict(state_dict_3, strict=False)\n",
    "model4.load_state_dict(state_dict_4, strict=False)\n",
    "model5.load_state_dict(state_dict_5, strict=False)\n",
    "model6.load_state_dict(state_dict_6, strict=False)\n",
    "\n",
    "# GPU 사용이 가능한 경우에는 GPU로 데이터 이동\n",
    "device1 = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device2 = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device3 = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device4 = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device5 = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device6 = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# b5=b5Model.to(b5Device)\n",
    "# mob=mobModel.to(mobDevice)\n",
    "# print(b5+mob)\n",
    "model1.to(device1)\n",
    "model2.to(device2)\n",
    "model3.to(device3)\n",
    "model4.to(device4)\n",
    "model5.to(device4)\n",
    "model6.to(device4)\n",
    "# print(mobModel.to(mobDevice))\n",
    "# print(b5Model.to(b5Device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 리스트 초기화\n",
    "result1 = []\n",
    "result2=[]\n",
    "result3=[]\n",
    "result4=[]\n",
    "result5=[]\n",
    "result6=[]\n",
    "\n",
    "all_result=[]\n",
    "or_result=[]\n",
    "and_result=[]\n",
    "vote_result=[]\n",
    "\n",
    "with torch.no_grad(): # 역전파 비활성화, 파라미터 업데이트 금지\n",
    "    # print(len(test_dataloader))\n",
    "    for images in tqdm(test_dataloader): # 데이터 로드\n",
    "        images = images.float().to(device) \n",
    "\n",
    "        outputs1 = model1(images) # 테스트 이미지 전달하여 예측 결과 얻음\n",
    "        outputs2 = model2(images) # 테스트 이미지 전달하여 예측 결과 얻음\n",
    "        outputs3 = model3(images) # 테스트 이미지 전달하여 예측 결과 얻음\n",
    "        outputs4 = model4(images) # 테스트 이미지 전달하여 예측 결과 얻음\n",
    "        outputs5 = model5(images) # 테스트 이미지 전달하여 예측 결과 얻음\n",
    "        outputs6 = model6(images)['out'] # 테스트 이미지 전달하여 예측 결과 얻음\n",
    "\n",
    "        masks1 = torch.sigmoid(outputs1).cpu().numpy() # outputs는 모델 예측 결과, 확률값으로 변환하기 위해 시그모이드 함수 적용한 후 각 픽셀 값을 0과 1사이의 확률값으로 변환하고, 넘파이 배열로 변환\n",
    "        masks2 = torch.sigmoid(outputs2).cpu().numpy() # outputs는 모델 예측 결과, 확률값으로 변환하기 위해 시그모이드 함수 적용한 후 각 픽셀 값을 0과 1사이의 확률값으로 변환하고, 넘파이 배열로 변환\n",
    "        masks3 = torch.sigmoid(outputs3).cpu().numpy() # outputs는 모델 예측 결과, 확률값으로 변환하기 위해 시그모이드 함수 적용한 후 각 픽셀 값을 0과 1사이의 확률값으로 변환하고, 넘파이 배열로 변환\n",
    "        masks4 = torch.sigmoid(outputs4).cpu().numpy() # outputs는 모델 예측 결과, 확률값으로 변환하기 위해 시그모이드 함수 적용한 후 각 픽셀 값을 0과 1사이의 확률값으로 변환하고, 넘파이 배열로 변환\n",
    "        masks5 = torch.sigmoid(outputs5).cpu().numpy() # outputs는 모델 예측 결과, 확률값으로 변환하기 위해 시그모이드 함수 적용한 후 각 픽셀 값을 0과 1사이의 확률값으로 변환하고, 넘파이 배열로 변환\n",
    "        masks6 = torch.sigmoid(outputs6).cpu().numpy() # outputs는 모델 예측 결과, 확률값으로 변환하기 위해 시그모이드 함수 적용한 후 각 픽셀 값을 0과 1사이의 확률값으로 변환하고, 넘파이 배열로 변환\n",
    "\n",
    "        # 두 모델의 예측 결과를 다수결 방식으로 합치기\n",
    "        ensemble_predictions = (outputs1 + outputs2 + outputs3 + outputs4 + outputs5+outputs6) >= 5  # 두 모델의 예측이 1 이상이면 True, 아니면 False\n",
    "\n",
    "        allMasks= masks1*0.16+masks2*0.37+masks3*0.16+masks4*0.16+masks5*0.15\n",
    "        # allMasks= masks2*0.65+masks6*0.35\n",
    "        # allMasks= ((masks1*0.7+masks2*0.2)+(masks1*0.8+masks3*0.2))/2\n",
    "\n",
    "        masks1 = np.squeeze(masks1, axis=1) # 불필요한 차원 제거\n",
    "        masks1 = (masks1 > 0.35).astype(np.uint8) # 최종 이진화 예측 마스크 얻음\n",
    "        \n",
    "        masks2 = np.squeeze(masks2, axis=1) # 불필요한 차원 제거\n",
    "        masks2 = (masks2 > 0.35).astype(np.uint8) # 최종 이진화 예측 마스크 얻음\n",
    "\n",
    "        masks3 = np.squeeze(masks3, axis=1) # 불필요한 차원 제거\n",
    "        masks3 = (masks3 > 0.35).astype(np.uint8) # 최종 이진화 예측 마스크 얻음\n",
    "\n",
    "        masks4 = np.squeeze(masks4, axis=1) # 불필요한 차원 제거\n",
    "        masks4 = (masks4 > 0.35).astype(np.uint8) # 최종 이진화 예측 마스크 얻음\n",
    "\n",
    "        masks5 = np.squeeze(masks5, axis=1) # 불필요한 차원 제거\n",
    "        masks5 = (masks5 > 0.35).astype(np.uint8) # 최종 이진화 예측 마스크 얻음\n",
    "\n",
    "        masks6 = np.squeeze(masks6, axis=1) # 불필요한 차원 제거\n",
    "        masks6 = (masks6 > 0.35).astype(np.uint8) # 최종 이진화 예측 마스크 얻음\n",
    "        \n",
    "        # print(len(images))\n",
    "        allMasks = np.squeeze(allMasks, axis=1) # 불필요한 차원 제거\n",
    "        allMasks = (allMasks > 0.30).astype(np.uint8) # 최종 이진화 예측 마스크 얻음\n",
    "\n",
    "        # # print(type(b5Masks))\n",
    "        # orMasks=np.logical_or(masks1,masks2)\n",
    "        # orMasks=np.logical_or(orMasks,masks3)\n",
    "        # orMasks=np.logical_or(orMasks,masks4)\n",
    "\n",
    "        # andMasks=np.logical_and(masks1,masks2)\n",
    "        # andMasks=np.logical_and(andMasks,masks3)\n",
    "        # andMasks=np.logical_and(andMasks,masks3)\n",
    "\n",
    "        # for i in range(len(images)):\n",
    "        #     mask_rle1 = rle_encode(masks1[i]) # RLE로 변환, mask_rle에 인코딩 결과 저장\n",
    "\n",
    "        #     if mask_rle1 == '':\n",
    "        #         result1.append(-1) # 빌딩 없으면 -1 저장\n",
    "        #     else:\n",
    "        #         result1.append(mask_rle1) # 아니면 mask_rle 저장\n",
    "\n",
    "        # for i in range(len(images)):\n",
    "        #     mask_rle2 = rle_encode(masks2[i]) # RLE로 변환, mask_rle에 인코딩 결과 저장\n",
    "\n",
    "        #     if mask_rle2 == '':\n",
    "        #         result2.append(-1) # 빌딩 없으면 -1 저장\n",
    "        #     else:\n",
    "        #         result2.append(mask_rle2) # 아니면 mask_rle 저장\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            all_mask_rle = rle_encode(allMasks[i]) # RLE로 변환, mask_rle에 인코딩 결과 저장\n",
    "\n",
    "            if all_mask_rle == '':\n",
    "                all_result.append(-1) # 빌딩 없으면 -1 저장\n",
    "            else:\n",
    "                all_result.append(all_mask_rle) # 아니면 mask_rle 저장\n",
    "        \n",
    "\n",
    "        # for i in range(len(images)):\n",
    "        #     or_mask_rle = rle_encode(orMasks[i]) # RLE로 변환, mask_rle에 인코딩 결과 저장\n",
    "\n",
    "        #     if or_mask_rle == '':\n",
    "        #         or_result.append(-1) # 빌딩 없으면 -1 저장\n",
    "        #     else:\n",
    "        #         or_result.append(or_mask_rle) # 아니면 mask_rle 저장\n",
    "\n",
    "        # for i in range(len(images)):\n",
    "        #     and_mask_rle = rle_encode(andMasks[i]) # RLE로 변환, mask_rle에 인코딩 결과 저장\n",
    "\n",
    "        #     if and_mask_rle == '':\n",
    "        #         and_result.append(-1) # 빌딩 없으면 -1 저장\n",
    "        #     else:\n",
    "        #         and_result.append(and_mask_rle) # 아니면 mask_rle 저장     \n",
    "\n",
    "        for i in range(len(images)):\n",
    "            ensemble_predictions_cpu = ensemble_predictions[i].cpu()  # Move the tensor to CPU\n",
    "            vote_mask_rle = rle_encode(ensemble_predictions_cpu)  # RLE로 변환, mask_rle에 인코딩 결과 저장\n",
    "\n",
    "            if vote_mask_rle == '':\n",
    "                vote_result.append(-1)  # 빌딩 없으면 -1 저장\n",
    "            else:\n",
    "                vote_result.append(vote_mask_rle)  # 아니면 mask_rle 저장\n",
    "\n",
    "            visualized_image = images[i].cpu().numpy().transpose((1, 2, 0)) # 이미지 시각화하기 위해 넘파이 배열로 가져옴\n",
    "            masks_visualized1 = masks1[i] * 255 # 이진화 마스크로 변환\n",
    "            masks_visualized2 = masks2[i] * 255 # 이진화 마스크로 변환\n",
    "            masks_visualized3 = masks3[i] * 255 # 이진화 마스크로 변환\n",
    "            masks_visualized4 = masks4[i] * 255 # 이진화 마스크로 변환\n",
    "            masks_visualized5 = masks5[i] * 255 # 이진화 마스크로 변환\n",
    "\n",
    "            pre_masks_visualized = ensemble_predictions_cpu.numpy().squeeze() * 255  # 이진화 마스크로 변환\n",
    "            all_masks_visualized = allMasks[i] * 255 # 이진화 마스크로 변환\n",
    "            # or_masks_visualized = orMasks[i] * 255 # 이진화 마스크로 변환\n",
    "            # and_masks_visualized = andMasks[i] * 255 # 이진화 마스크로 변환\n",
    "\n",
    "            # plt.figure(figsize=(15, 10))  # 원하는 크기로 조정\n",
    "\n",
    "            # plt.subplot(1, 7, 1)\n",
    "            # plt.imshow(visualized_image)\n",
    "            # plt.title(\"Input Image\")\n",
    "\n",
    "            # plt.subplot(1, 7, 2)\n",
    "            # plt.imshow(masks_visualized1, cmap='gray')\n",
    "            # plt.title(\"152\")\n",
    "\n",
    "            # plt.subplot(1, 7, 3)\n",
    "            # plt.imshow(masks_visualized2, cmap='gray')\n",
    "            # plt.title(\"dense\")\n",
    "\n",
    "            # plt.subplot(1, 7, 4)\n",
    "            # plt.imshow(masks_visualized3, cmap='gray')\n",
    "            # plt.title(\"50\")\n",
    "\n",
    "            # plt.subplot(1, 7, 5)\n",
    "            # plt.imshow(masks_visualized4, cmap='gray')\n",
    "            # plt.title(\"mobilenet\")\n",
    "\n",
    "            # plt.subplot(1, 7, 6)\n",
    "            # plt.imshow(pre_masks_visualized, cmap='gray')\n",
    "            # plt.title(\"vote\")\n",
    "\n",
    "            # plt.subplot(1, 7, 7)\n",
    "            # plt.imshow(all_masks_visualized, cmap='gray')\n",
    "            # plt.title(\"all\")\n",
    "            # plt.subplot(1, 6, 5)\n",
    "            # plt.imshow(or_masks_visualized, cmap='gray')\n",
    "            # plt.title(\"or Mask\")\n",
    "\n",
    "            # plt.subplot(1, 6, 6)\n",
    "            # plt.imshow(and_masks_visualized, cmap='gray')\n",
    "            # plt.title(\"and Mask\")\n",
    "\n",
    "            # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./validation_sample.csv')\n",
    "submit['mask_rle'] = all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./152_dense_50_v3plus_v3/all_validation_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./validation_sample.csv')\n",
    "submit['mask_rle'] = vote_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./152_dense_50_v3plus_v3/vote_validation_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./validation_sample.csv')\n",
    "submit['mask_rle'] = or_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./psp_resnet_dense_unet_resnet_vote/or_validation_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./validation_sample.csv')\n",
    "submit['mask_rle'] = and_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./psp_resnet_dense_unet_resnet_vote/and_validation_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtorch",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
